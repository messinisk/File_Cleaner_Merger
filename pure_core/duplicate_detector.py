"""
duplicate detection : Î±Î½Î¯Ï‡Î½ÎµÏ…ÏƒÎ· Î´Î¹Ï€Î»Î¿Ï„ÏÏ€Ï‰Î½
Î•ÏƒÏ„Î¹Î¬Î¶ÎµÎ¹ ÏƒÏ„Î¿Î½ ÎµÎ½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒ Î´Î¹Ï€Î»ÏŒÏ„Ï…Ï€Ï‰Î½ Î±ÏÏ‡ÎµÎ¯Ï‰Î½ ÏƒÎµ Î­Î½Î±Î½ Ï†Î¬ÎºÎµÎ»Î¿. :
It focuses on identifying duplicate files in a folder.
    Returns:
        _type_: _description_
"""

import hashlib
import logging
import os
from asyncio.log import logger
from collections import defaultdict
from datetime import datetime

from pure_core.exclusion_config import is_excluded_dir, is_system_path

# -------------------------------
# ğŸ”§ Î¡ÏÎ¸Î¼Î¹ÏƒÎ· Ï„Î¿Ï… logging
# -------------------------------
logging.basicConfig(
    filename="file_inspector.log",
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)


# -------------------------------
# ğŸ” Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ hash Î±ÏÏ‡ÎµÎ¯Î¿Ï…
# -------------------------------


def file_hash(path):  # type: ignore
    """Î¥Ï€Î¿Î»Î¿Î³Î¯Î¶ÎµÎ¹ SHA256 hash Ï„Î¿Ï… Î±ÏÏ‡ÎµÎ¯Î¿Ï…."""
    hasher = hashlib.sha256()
    with open(path, "rb") as f:  # type: ignore
        while chunk := f.read(8192):
            hasher.update(chunk)
    return hasher.hexdigest()


def get_file_metadata(path):  # type: ignore
    """Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ ÏŒÎ½Î¿Î¼Î±, Î´Î¹Î±Î´ÏÎ¿Î¼Î®, hash, Î·Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î± Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î±Ï‚/Ï„ÏÎ¿Ï€Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚."""
    try:
        stat = os.stat(path)  # type: ignore
        return {
            "name": os.path.basename(path),  # type: ignore
            "path": path,
            "hash": file_hash(path),  # type: ignore
            "created": datetime.fromtimestamp(stat.st_ctime),
            "modified": datetime.fromtimestamp(stat.st_mtime),
        }
    except Exception as e:
        logging.warning(
            f"Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬\
            Ï„Î·Î½ Î±Î½Î¬Î³Î½Ï‰ÏƒÎ· Ï„Î¿Ï… Î±ÏÏ‡ÎµÎ¯Î¿Ï…: {path} -> {e}"
        )
        return None


def inspect_directory_state(base_path: str) -> list[dict]:  # type: ignore
    """
    Î£Î±ÏÏÎ½ÎµÎ¹ Ï†Î¬ÎºÎµÎ»Î¿ ÎºÎ±Î¹ ÎµÎ½Ï„Î¿Ï€Î¯Î¶ÎµÎ¹ Î±ÏÏ‡ÎµÎ¯Î± Î¼Îµ:
    - Î¯Î´Î¹Î¿ ÏŒÎ½Î¿Î¼Î±
    - Î¯Î´Î¹Î¿ Î® Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÏŒ Ï€ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿ (Ï‰Ï‚ ÎµÎºÎ´ÏŒÏƒÎµÎ¹Ï‚)
    - Î¯Î´Î¹Î± Î·Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î± Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î±Ï‚
    """
    base_path = os.path.abspath(base_path)

    if not is_valid_directory(base_path):  # pyright: ignore[reportCallIssue, reportArgumentType]
        return []

    file_info_list = collect_file_info(base_path)  # pyright: ignore[reportCallIssue, reportArgumentType]
    log_skipped_files(base_path)  # pyright: ignore[reportCallIssue, reportArgumentType]
    name_map = group_files_by_name(file_info_list)
    analyze_duplicate_groups(name_map)

    return file_info_list


def is_valid_directory(path: str) -> bool:
    """Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ True Î±Î½ Î· Î´Î¹Î±Î´ÏÎ¿Î¼Î® ÎµÎ¯Î½Î±Î¹\
    Î­Î³ÎºÏ…ÏÎ¿Ï‚ Ï†Î¬ÎºÎµÎ»Î¿Ï‚, Î±Î»Î»Î¹ÏÏ‚ ÎºÎ¬Î½ÎµÎ¹ log ÎºÎ±Î¹ False."""
    if not os.path.isdir(path):
        logging.error(f"Î— Î´Î¹Î±Î´ÏÎ¿Î¼Î® Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î­Î³ÎºÏ…ÏÎ¿Ï‚ Ï†Î¬ÎºÎµÎ»Î¿Ï‚: {path}")
        return False
    return True


def collect_file_info(base_path: str) -> list[dict]:
    """
    Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Î»Î¯ÏƒÏ„Î± Î¼ÎµÏ„Î±Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î³Î¹Î± ÎºÎ¬Î¸Îµ Î±ÏÏ‡ÎµÎ¯Î¿\
    Î¼Î­ÏƒÎ± ÏƒÎµ Î­Î½Î±Î½ Ï†Î¬ÎºÎµÎ»Î¿ ÎºÎ±Î¹ Ï„Î¿Ï…Ï‚ Ï…Ï€Î¿Ï†Î±ÎºÎ­Î»Î¿Ï…Ï‚ Ï„Î¿Ï….

    Î‘Î³Î½Î¿ÎµÎ¯:
    - Î¦Î±ÎºÎ­Î»Î¿Ï…Ï‚ Ï€Î¿Ï… ÎºÎ±Î¸Î¿ÏÎ¯Î¶Î¿Î½Ï„Î±Î¹ Ï‰Ï‚ Î±Ï€Î¿ÎºÎ»ÎµÎ¹ÏƒÎ¼Î­Î½Î¿Î¹\
    Î±Ï€ÏŒ Ï„Î· ÏÏÎ¸Î¼Î¹ÏƒÎ· (exclusion_config)
    - Î£Ï…ÏƒÏ‡ÎµÏ„Î¹ÏƒÎ¼Î­Î½Î¿Ï…Ï‚ Ï†Î±ÎºÎ­Î»Î¿Ï…Ï‚ Ï„Î¿Ï… ÏƒÏ…ÏƒÏ„Î®Î¼Î±Ï„Î¿Ï‚\
    (ÏŒÏ€Ï‰Ï‚ Python env, system dirs)

    Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹:
    - Î›Î¯ÏƒÏ„Î± Î±Ï€ÏŒ Î»ÎµÎ¾Î¹ÎºÎ¬ Î¼Îµ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Î³Î¹Î± ÎºÎ¬Î¸Îµ Î­Î³ÎºÏ…ÏÎ¿ Î±ÏÏ‡ÎµÎ¯Î¿\
    (Ï€.Ï‡. ÏŒÎ½Î¿Î¼Î±, Î´Î¹Î±Î´ÏÎ¿Î¼Î®, Î¼Î­Î³ÎµÎ¸Î¿Ï‚, hash Îº.Î¬.)
    """
    return [
        metadata
        for root, _, files in os.walk(base_path)
        if not is_excluded_dir(root) and not is_system_path(root)
        for file in files
        if os.path.isfile(full_path := os.path.join(root, file))
        if (metadata := get_file_metadata(full_path))  # pyright: ignore[reportArgumentType] # pyright: ignore[reportCallIssue] # pyright: ignore[reportCallIssue] # pyright: ignore[reportCallIssue] # pyright: ignore[reportCallIssue] # pyright: ignore[reportCallIssue] # pyright: ignore[reportCallIssue] # pyright: ignore[reportCallIssue] # pyright: ignore[reportCallIssue] # pyright: ignore[reportCallIssue] # pyright: ignore[reportCallIssue] # pyright: ignore[reportCallIssue] # pyright: ignore[reportCallIssue] # type: ignore
    ]


def log_skipped_files(base_path: str) -> None:
    """ÎšÎ¬Î½ÎµÎ¹ logging Î³Î¹Î± ÎºÎ¬Î¸Îµ ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î¿ Ï€Î¿Ï… Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î±ÏÏ‡ÎµÎ¯Î¿."""
    for root, _, files in os.walk(base_path):
        for file in files:
            full_path = os.path.join(root, file)
            if not os.path.isfile(full_path):
                logging.warning(f"Î Î±ÏÎ±Î»ÎµÎ¯Ï†Î¸Î·ÎºÎµ (Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î±ÏÏ‡ÎµÎ¯Î¿): {full_path}")


def group_files_by_name(file_info_list: list[dict]) -> dict[str, list[dict]]:
    """ÎŸÎ¼Î±Î´Î¿Ï€Î¿Î¹ÎµÎ¯ Ï„Î± Î±ÏÏ‡ÎµÎ¯Î± Î¼Îµ Î²Î¬ÏƒÎ· Ï„Î¿ ÏŒÎ½Î¿Î¼Î¬ Ï„Î¿Ï…Ï‚."""
    name_map: dict[str, list[dict]] = defaultdict(list)
    for info in file_info_list:
        name_map[info["name"]].append(info)
    return name_map


def analyze_duplicate_groups(name_map: dict[str, list[dict]]) -> None:
    """Î‘Î½Î±Î»ÏÎµÎ¹ Ï„Î± Î±ÏÏ‡ÎµÎ¯Î± Î¼Îµ Î¯Î´Î¹Î¿ ÏŒÎ½Î¿Î¼Î± ÎºÎ±Î¹ ÎºÎ±Ï„Î±Î³ÏÎ¬Ï†ÎµÎ¹ Î±Î½ ÎµÎ¯Î½Î±Î¹ Î¯Î´Î¹Î± Î® Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¬."""
    for name, files in name_map.items():
        if not should_analyze_group(files):
            continue

        versions = group_files_by_hash(files)  # pyright: ignore[reportCallIssue, reportArgumentType]
        if len(versions) == 1:
            log_identical_group(name)  # pyright: ignore[reportArgumentType, reportCallIssue]
        else:
            log_versioned_group(name, versions)  # pyright: ignore[reportCallIssue]


def should_analyze_group(files: list[dict]) -> bool:
    """Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ True Î±Î½ Î· Î»Î¯ÏƒÏ„Î± Î­Ï‡ÎµÎ¹ Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎ± Î±Ï€ÏŒ 1 Î±ÏÏ‡ÎµÎ¯Î±."""
    return len(files) > 1


def log_identical_group(name: str) -> None:
    """ÎšÎ±Ï„Î±Î³ÏÎ¬Ï†ÎµÎ¹ ÏŒÏ„Î¹ ÏŒÎ»Î± Ï„Î± Î±ÏÏ‡ÎµÎ¯Î± ÎµÎ¯Î½Î±Î¹ Î¯Î´Î¹Î±."""
    logger.info(f"Î‘ÏÏ‡ÎµÎ¯Î¿ '{name}' Î­Ï‡ÎµÎ¹ Î¯Î´Î¹Î¿ Ï€ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿ ÏƒÎµ ÏŒÎ»ÎµÏ‚ Ï„Î¹Ï‚ Ï„Î¿Ï€Î¿Î¸ÎµÏƒÎ¯ÎµÏ‚.")


def log_versioned_group(name: str, versions: dict[str, list[dict]]) -> None:
    """ÎšÎ±Ï„Î±Î³ÏÎ¬Ï†ÎµÎ¹ Ï„Î¹Ï‚ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ­Ï‚ ÎµÎºÎ´ÏŒÏƒÎµÎ¹Ï‚ Ï„Î¿Ï… Î±ÏÏ‡ÎµÎ¯Î¿Ï…."""
    logger.info(f"Î‘ÏÏ‡ÎµÎ¯Î¿ '{name}' Î­Ï‡ÎµÎ¹ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ­Ï‚ ÎµÎºÎ´ÏŒÏƒÎµÎ¹Ï‚:")
    for version_hash, version_files in versions.items():
        for vf in version_files:
            logger.info(
                f"ÎˆÎºÎ´Î¿ÏƒÎ· '{name}' | hash: {version_hash[:10]} | ğŸ•’ {vf['modified']} | ğŸ“ {vf['path']}"
            )


def group_files_by_hash(files: list[dict]) -> dict[str, list[dict]]:
    """ÎŸÎ¼Î±Î´Î¿Ï€Î¿Î¹ÎµÎ¯ Î±ÏÏ‡ÎµÎ¯Î± Î¼Îµ Î²Î¬ÏƒÎ· Ï„Î¿ hash."""
    versions: dict[str, list[dict]] = defaultdict(list)
    for f in files:
        versions[f["hash"]].append(f)
    return versions


def get_all_file_info(
    path: str,
) -> list[dict]:  # pyright: ignore[reportMissingTypeArgument, reportUnknownParameterType]
    """Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Î³Î¹Î± ÎºÎ¬Î¸Îµ Î±ÏÏ‡ÎµÎ¯Î¿ ÏƒÎµ Î¼Î¹Î± Î´Î¹Î±Î´ÏÎ¿Î¼Î®."""
    file_infos = []
    for root, _, files in os.walk(path):
        for file in files:
            full_path = os.path.join(root, file)
            try:
                with open(full_path, "rb") as f:
                    content = f.read()
                    file_hash = hashlib.sha256(content).hexdigest()
                    created = os.path.getctime(full_path)
                    file_infos.append(
                        {  # pyright: ignore[reportUnknownMemberType]
                            "name": file,
                            "path": full_path,
                            "hash": file_hash,
                            "created": created,
                        }
                    )
            except (IOError, OSError) as e:
                logger.warning("Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î·Î½ Î±Î½Î¬Î³Î½Ï‰ÏƒÎ· Î±ÏÏ‡ÎµÎ¯Î¿Ï…: %s", e)
                continue  # Î‘Î½ ÎºÎ¬Ï€Î¿Î¹Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ Î´ÎµÎ½ Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Î´Î¹Î±Î²Î±ÏƒÏ„ÎµÎ¯, Î±Ï€Î»ÏÏ‚ Ï„Î¿ Ï€Î±ÏÎ±Î»ÎµÎ¯Ï€Î¿Ï…Î¼Îµ
    return file_infos  # pyright: ignore[reportUnknownVariableType]


def group_duplicates(
    file_infos: list[dict],
) -> list[list[dict]]:  # pyright: ignore[reportMissingTypeArgument, reportUnknownParameterType]
    """ÎŸÎ¼Î±Î´Î¿Ï€Î¿Î¹ÎµÎ¯ Î±ÏÏ‡ÎµÎ¯Î± Î¼Îµ Î²Î¬ÏƒÎ· Ï„Î¿ hash."""
    grouped = defaultdict(list)  # pyright: ignore[reportUnknownVariableType]
    for info in file_infos:  # pyright: ignore[reportUnknownVariableType]
        grouped[info["hash"]].append(info)

    return list(grouped.values())  # pyright: ignore[reportUnknownArgumentType, reportUnknownVariableType]

# Î•ÏƒÏ„Î¹Î¬Î¶ÎµÎ¹ ÏƒÏ„Î¿Î½ ÎµÎ½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒ Î´Î¹Ï€Î»ÏŒÏ„Ï…Ï€Ï‰Î½
import hashlib
import logging
import os
from collections import defaultdict
from datetime import datetime
from exclusion_config import is_excluded_dir, is_system_path


# -------------------------------
# ğŸ”§ Î¡ÏÎ¸Î¼Î¹ÏƒÎ· Ï„Î¿Ï… logging
# -------------------------------
logging.basicConfig(
    filename="file_inspector.log",
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)


# -------------------------------
# ğŸ” Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ hash Î±ÏÏ‡ÎµÎ¯Î¿Ï…
# -------------------------------
def file_hash(path):  # type: ignore
    """Î¥Ï€Î¿Î»Î¿Î³Î¯Î¶ÎµÎ¹ SHA256 hash Ï„Î¿Ï… Î±ÏÏ‡ÎµÎ¯Î¿Ï…."""
    hasher = hashlib.sha256()
    with open(path, "rb") as f:  # type: ignore
        while chunk := f.read(8192):
            hasher.update(chunk)
    return hasher.hexdigest()


# -------------------------------
# ğŸ“„ Î‘Î½Î¬ÎºÏ„Î·ÏƒÎ· Î¼ÎµÏ„Î±Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î±ÏÏ‡ÎµÎ¯Î¿Ï…
# -------------------------------
def get_file_metadata(path):  # type: ignore
    """Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ ÏŒÎ½Î¿Î¼Î±, Î´Î¹Î±Î´ÏÎ¿Î¼Î®, hash, Î·Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î± Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î±Ï‚/Ï„ÏÎ¿Ï€Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚."""
    try:
        stat = os.stat(path)  # type: ignore
        return {
            "name": os.path.basename(path),  # type: ignore
            "path": path,
            "hash": file_hash(path),  # type: ignore
            "created": datetime.fromtimestamp(stat.st_ctime),
            "modified": datetime.fromtimestamp(stat.st_mtime),
        }
    except Exception as e:
        logging.error(f"Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î·Î½ Î±Î½Î¬Î³Î½Ï‰ÏƒÎ· Ï„Î¿Ï… Î±ÏÏ‡ÎµÎ¯Î¿Ï…: {path} -> {e}")
        return None


# -------------------------------
# ğŸ§© ÎšÏÏÎ¹Î± ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· ÏƒÎ¬ÏÏ‰ÏƒÎ·Ï‚ Ï†Î±ÎºÎ­Î»Î¿Ï…
# -------------------------------
def inspect_directory_state(base_path: str) -> list[dict]:  # type: ignore
    """
    Î£Î±ÏÏÎ½ÎµÎ¹ Ï†Î¬ÎºÎµÎ»Î¿ ÎºÎ±Î¹ ÎµÎ½Ï„Î¿Ï€Î¯Î¶ÎµÎ¹ Î±ÏÏ‡ÎµÎ¯Î± Î¼Îµ:
    - Î¯Î´Î¹Î¿ ÏŒÎ½Î¿Î¼Î±
    - Î¯Î´Î¹Î¿ Î® Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÏŒ Ï€ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿ (Ï‰Ï‚ ÎµÎºÎ´ÏŒÏƒÎµÎ¹Ï‚)
    - Î¯Î´Î¹Î± Î·Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î± Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î±Ï‚
    """
    base_path = os.path.abspath(base_path)

    if not is_valid_directory(base_path):
        return []

    file_info_list = collect_file_info(base_path)
    log_skipped_files(base_path)
    name_map = group_files_by_name(file_info_list)
    analyze_duplicate_groups(name_map)

    return file_info_list


def is_valid_directory(path: str) -> bool:
    """Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ True Î±Î½ Î· Î´Î¹Î±Î´ÏÎ¿Î¼Î® ÎµÎ¯Î½Î±Î¹ Î­Î³ÎºÏ…ÏÎ¿Ï‚ Ï†Î¬ÎºÎµÎ»Î¿Ï‚, Î±Î»Î»Î¹ÏÏ‚ ÎºÎ¬Î½ÎµÎ¹ log ÎºÎ±Î¹ False."""
    if not os.path.isdir(path):
        logging.error(f"Î— Î´Î¹Î±Î´ÏÎ¿Î¼Î® Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î­Î³ÎºÏ…ÏÎ¿Ï‚ Ï†Î¬ÎºÎµÎ»Î¿Ï‚: {path}")
        return False
    return True


def collect_file_info(base_path: str) -> list[dict]:
    file_info_list = []
    for root, _, files in os.walk(base_path):
        if is_excluded_dir(root) or is_system_path(root):
            logging.warning(f"â›” Î‘Î³Î½Î¿Î®Î¸Î·ÎºÎµ Ï†Î¬ÎºÎµÎ»Î¿Ï‚ ÏƒÏ…ÏƒÏ„Î®Î¼Î±Ï„Î¿Ï‚ Î® Î±Ï€Î¿ÎºÎ»ÎµÎ¹ÏƒÎ¼Î­Î½Î¿Ï‚: {root}")
            continue
        for file in files:
            full_path = os.path.join(root, file)
            if os.path.isfile(full_path):
                metadata = get_file_metadata(full_path)
                if metadata:
                    file_info_list.append(metadata)
    return file_info_list


def log_skipped_files(base_path: str) -> None:
    """ÎšÎ¬Î½ÎµÎ¹ logging Î³Î¹Î± ÎºÎ¬Î¸Îµ ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î¿ Ï€Î¿Ï… Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î±ÏÏ‡ÎµÎ¯Î¿."""
    for root, _, files in os.walk(base_path):
        for file in files:
            full_path = os.path.join(root, file)
            if not os.path.isfile(full_path):
                logging.warning(f"Î Î±ÏÎ±Î»ÎµÎ¯Ï†Î¸Î·ÎºÎµ (Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î±ÏÏ‡ÎµÎ¯Î¿): {full_path}")


def group_files_by_name(file_info_list: list[dict]) -> dict[str, list[dict]]:
    """ÎŸÎ¼Î±Î´Î¿Ï€Î¿Î¹ÎµÎ¯ Ï„Î± Î±ÏÏ‡ÎµÎ¯Î± Î¼Îµ Î²Î¬ÏƒÎ· Ï„Î¿ ÏŒÎ½Î¿Î¼Î¬ Ï„Î¿Ï…Ï‚."""
    name_map: dict[str, list[dict]] = defaultdict(list)
    for info in file_info_list:
        name_map[info["name"]].append(info)
    return name_map


def analyze_duplicate_groups(name_map: dict[str, list[dict]]) -> None:
    """Î‘Î½Î±Î»ÏÎµÎ¹ Ï„Î± Î±ÏÏ‡ÎµÎ¯Î± Î¼Îµ Î¯Î´Î¹Î¿ ÏŒÎ½Î¿Î¼Î± ÎºÎ±Î¹ ÎºÎ±Ï„Î±Î³ÏÎ¬Ï†ÎµÎ¹ Î±Î½ ÎµÎ¯Î½Î±Î¹ Î¯Î´Î¹Î± Î® Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¬."""
    for name, files in name_map.items():
        if not should_analyze_group(files):
            continue

        versions = group_files_by_hash(files)
        if len(versions) == 1:
            log_identical_group(name)
        else:
            log_versioned_group(name, versions)


def should_analyze_group(files: list[dict]) -> bool:
    """Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ True Î±Î½ Î· Î»Î¯ÏƒÏ„Î± Î­Ï‡ÎµÎ¹ Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎ± Î±Ï€ÏŒ 1 Î±ÏÏ‡ÎµÎ¯Î±."""
    return len(files) > 1


def log_identical_group(name: str) -> None:
    """ÎšÎ±Ï„Î±Î³ÏÎ¬Ï†ÎµÎ¹ ÏŒÏ„Î¹ ÏŒÎ»Î± Ï„Î± Î±ÏÏ‡ÎµÎ¯Î± ÎµÎ¯Î½Î±Î¹ Î¯Î´Î¹Î±."""
    logging.info(f"Î‘ÏÏ‡ÎµÎ¯Î¿ '{name}' Î­Ï‡ÎµÎ¹ Î¯Î´Î¹Î¿ Ï€ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿ ÏƒÎµ ÏŒÎ»ÎµÏ‚ Ï„Î¹Ï‚ Ï„Î¿Ï€Î¿Î¸ÎµÏƒÎ¯ÎµÏ‚.")


def log_versioned_group(name: str, versions: dict[str, list[dict]]) -> None:
    """ÎšÎ±Ï„Î±Î³ÏÎ¬Ï†ÎµÎ¹ Ï„Î¹Ï‚ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ­Ï‚ ÎµÎºÎ´ÏŒÏƒÎµÎ¹Ï‚ Ï„Î¿Ï… Î±ÏÏ‡ÎµÎ¯Î¿Ï…."""
    logging.info(f"Î‘ÏÏ‡ÎµÎ¯Î¿ '{name}' Î­Ï‡ÎµÎ¹ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ­Ï‚ ÎµÎºÎ´ÏŒÏƒÎµÎ¹Ï‚:")
    for version_hash, version_files in versions.items():
        for vf in version_files:
            logging.info(
                f"ÎˆÎºÎ´Î¿ÏƒÎ· '{name}' | hash: {version_hash[:10]} | ğŸ•’ {vf['modified']} | ğŸ“ {vf['path']}"
            )


def group_files_by_hash(files: list[dict]) -> dict[str, list[dict]]:
    """ÎŸÎ¼Î±Î´Î¿Ï€Î¿Î¹ÎµÎ¯ Î±ÏÏ‡ÎµÎ¯Î± Î¼Îµ Î²Î¬ÏƒÎ· Ï„Î¿ hash."""
    versions: dict[str, list[dict]] = defaultdict(list)
    for f in files:
        versions[f["hash"]].append(f)
    return versions


def get_all_file_info(
    path: str,
) -> list[dict]:  # pyright: ignore[reportMissingTypeArgument, reportUnknownParameterType]
    """Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Î³Î¹Î± ÎºÎ¬Î¸Îµ Î±ÏÏ‡ÎµÎ¯Î¿ ÏƒÎµ Î¼Î¹Î± Î´Î¹Î±Î´ÏÎ¿Î¼Î®."""
    file_infos = []
    for root, _, files in os.walk(path):
        for file in files:
            full_path = os.path.join(root, file)
            try:
                with open(full_path, "rb") as f:
                    content = f.read()
                    file_hash = hashlib.sha256(content).hexdigest()
                    created = os.path.getctime(full_path)
                    file_infos.append(
                        {  # pyright: ignore[reportUnknownMemberType]
                            "name": file,
                            "path": full_path,
                            "hash": file_hash,
                            "created": created,
                        }
                    )
            except Exception as e:  # pyright: ignore[reportUnusedVariable]  # noqa: F841
                continue  # Î‘Î½ ÎºÎ¬Ï€Î¿Î¹Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ Î´ÎµÎ½ Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Î´Î¹Î±Î²Î±ÏƒÏ„ÎµÎ¯, Î±Ï€Î»ÏÏ‚ Ï„Î¿ Ï€Î±ÏÎ±Î»ÎµÎ¯Ï€Î¿Ï…Î¼Îµ
    return file_infos  # pyright: ignore[reportUnknownVariableType]


def group_duplicates(
    file_infos: list[dict],
) -> list[list[dict]]:  # pyright: ignore[reportMissingTypeArgument, reportUnknownParameterType]
    """ÎŸÎ¼Î±Î´Î¿Ï€Î¿Î¹ÎµÎ¯ Î±ÏÏ‡ÎµÎ¯Î± Î¼Îµ Î²Î¬ÏƒÎ· Ï„Î¿ hash."""
    grouped = defaultdict(list)  # pyright: ignore[reportUnknownVariableType]
    for info in file_infos:  # pyright: ignore[reportUnknownVariableType]
        grouped[info["hash"]].append(info)  # pyright: ignore[reportUnknownMemberType]

    return list(grouped.values())  # pyright: ignore[reportUnknownArgumentType, reportUnknownVariableType]


if __name__ == "__main__":
    print(inspect_directory_state("./"))  # type: ignore
